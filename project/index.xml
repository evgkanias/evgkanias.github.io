<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Evripidis Gkanias</title>
    <link>https://evgkanias.github.io/project/</link>
      <atom:link href="https://evgkanias.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-gb</language><copyright>© 2022 Evripidis Gkanias</copyright><lastBuildDate>Sat, 01 Sep 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://evgkanias.github.io/media/icon_hub0b98d3151be369414d13011ac1efa0e_21731_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://evgkanias.github.io/project/</link>
    </image>
    
    <item>
      <title>Circuits for navigation strategies inspired by insects</title>
      <link>https://evgkanias.github.io/project/phd-thesis/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/phd-thesis/</guid>
      <description>&lt;p&gt;We come up with a computational model of the insect mushroom body,
constrained by biological findings of the insect brain. This model is able
to acquire, forget and assimilate (transfer from short- to long-term)
associative memories, represent a spectrum of motivation for the
animal and drive its behaviour. We examine the capabilities of this
model as an olfactory conditioning system and as part of the insect
visual navigation mechanism&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploiting invisible cues for robot navigation in complex natural environments</title>
      <link>https://evgkanias.github.io/project/invisible-cues/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/invisible-cues/</guid>
      <description>&lt;p&gt;Outdoor navigation in natural environments remains a challenge for robotics.
Recent breakthroughs in robot navigation have been dependent on specific sensor
technologies, such as laser depth sensors and GPS, and advanced image processing.
The ability of animals such as ants to navigate effectively without such
power- and computation- hungry systems are a proof of principle that
alternative cheaper approaches are viable. Ants also have specialised sensing,
with a peripheral visual system that has evolved to be sensitive to crucial
cues for navigation. Specifically, they make use of non-visible (to humans)
light cues in the form of ultraviolet (UV) and polarised light detection.
UV detection allows the important signal of the horizon shape against the sky
to be easily distinguished. Polarised light detection provides an external
compass cue of heading relative to the sun direction, even when only a small
portion of the sky is visible.&lt;/p&gt;
&lt;p&gt;We propose to build a sensory system that gathers the full range of light
cues available to the ant, in its natural ecological situation, and to analyse
the information contained in this signal. We will also analyse how the
specific sensor layout (ommatidia array), peripheral receptor characteristics,
and the motor behaviour of the ant may contribute to extracting salient
information. The data will form a test-bed for comparison of algorithmic and
neural models of the processing that underlies the navigation capabilities
of the ant. To date, these cues have been considered separately but we believe
the navigational success of this system depends on the specific combination.
For example, the directional information in the polarised sky may form an
important part of visual memories; and UV information may contribute to
disambiguation of the polarisation pattern and the robustness of this
information under different cloud conditions.&lt;/p&gt;
&lt;p&gt;There has been a substantial increase in the last few years in research into
insect neural pathways involved in processing these cues which has yet to be
exploited in robot models. In particular there has been breakthrough work on
the central brain mechanisms involved in decoding polarised light to obtain
heading direction. There is also a rapidly increasing understanding of the
circuits involved in learning, a key component of navigation capabilities.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Miniature Insect Model for Active Learning (Minimal)</title>
      <link>https://evgkanias.github.io/project/minimal/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/minimal/</guid>
      <description>&lt;p&gt;Biology provides the inspiration for a vision of small low-power devices that are able to learn rapidly and autonomously about environmental contingencies, enabling prediction and adaptive anticipatory action. Larval Drosophila have fewer than 10,000 neurons, yet express a variety of complex orientation and learning behaviours, including non-trivial anticipatory actions requiring context-dependent evaluation of the value of learned cues. Current computational learning theory cannot fully account for or replicate these capacities. We aim to develop a new foundation for understanding natural learning by developing a complete multilevel model of learning in larvae.&lt;/p&gt;
&lt;p&gt;Our aims are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;to analyse at a fine scale how larval olfactory behaviour is controlled and altered by associative conditioning, linked to agent-based models that ground learning capabilities in ongoing sensorimotor control;&lt;/li&gt;
&lt;li&gt;to build one-to-one computational neural models that can be validated by exploiting the recent expansion of the Drosophila neurogenetic toolkit to gain unprecedented ability to characterise and manipulate neural circuits during unconstrained behaviour;&lt;/li&gt;
&lt;li&gt;to derive from these models novel, generalisable algorithms and circuit architectures that can be used to enhance the learning and anticipatory capabilities of machines.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Robocrab: data-driven adaptation of the evation behaviour in fiddler crabs</title>
      <link>https://evgkanias.github.io/project/msc-thesis/</link>
      <pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/msc-thesis/</guid>
      <description>&lt;p&gt;We create a semi-supervised structure of neural network, inspired by
the physiology of neurons in fiddler crabs, and train it to adapt the
evasion behaviour of fiddler crabs on potential predators, solving a
complicated visuomotor problem (developed in Python using the
Theano/Tensorflow-based ‘keras’ library&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Replay</title>
      <link>https://evgkanias.github.io/project/replay/</link>
      <pubDate>Mon, 31 Aug 2015 14:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/replay/</guid>
      <description>&lt;p&gt;The RePlay project has as its goal the development of a technology platform
that shall provide access and interpretation of digital content for Traditional
Sports and Games (TSG). It will enable multiple modes of training, coaching and
knowledge sharing that will contribute to the increased participation and preservation
of traditional sport in the future. This will be achieved by developing a base
technology and methodologies for the digitisation of the art and forms of play of a
set of representative sports. In the case of RePlay, this will be field based 
Gaelic team sports and Basque individual/doubles ball and court sports. 
The fundamental structure of these sports is extensible to a vast majority of traditional
minority sports and mainstream sports.&lt;/p&gt;
&lt;p&gt;RePlay will consist of the design and implementation of a platform for the capture, annotation, indexing and provision of 3D sports content. It will include the analysis and specification of methodologies and ideal cost-effective hardware solutions for the extension of the project to other sports. The project will focus on the use of existing and near future 3D motion capture hardware. The project does not include the development of any hardware as an objective, as the market is already addressing this. It shall instead focus on the creation of the knowledge and underlying software tools that will provide a low-cost entry point to other TSG associations.&lt;/p&gt;
&lt;p&gt;RePlay will focus on the analysis, capture and modelling of the basic styles and techniques of play common to all participants or the &amp;ldquo;Local Hero&amp;rdquo; using low-cost capture techniques. However, RePlay will also use advanced professional grade capture techniques on &amp;ldquo;National Heroes&amp;rdquo;. A national hero, or a recognised elite player, develops their sporting prowess to an extent that is unique. This presents Intangible Cultural Heritage to be preserved, an opportunity to allow the young to try to learn and emulate their heroes, and a scientific opportunity to compare and analyse the evolution in the changes of styles of play over time. RePlay will also include work on retrospective analysis of sports via video content.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep learning algorithms for multi-label data</title>
      <link>https://evgkanias.github.io/project/bsc-thesis/</link>
      <pubDate>Fri, 01 Feb 2013 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/bsc-thesis/</guid>
      <description>&lt;p&gt;We extended a Java library implementing Restricted Boltzmann Machines and
Deep Belief Networks and we used it to examine how they perform in a variety
of multi-label data-sets.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
