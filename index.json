[{"authors":null,"categories":null,"content":" Evripidis is a post-doctoral Research Fellow at Lund University.\nHe is interested in bio-accurate artificial intelligence and information theory. He currently investigates the effectiveness of the insects’ celestial compass and its adaptation to different environments. Inspired by insect neuroscience, he tries to build sensors and navigation systems that are robust to environmental disturbances.\nScientific questions he is currently working on:\nhow the celestial compass adapts to new environments, how it is integrated with other visual information, and how working memory implements in the brain. Download my resumé.","date":1742630400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1742630400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Evripidis is a post-doctoral Research Fellow at Lund University.\nHe is interested in bio-accurate artificial intelligence and information theory. He currently investigates the effectiveness of the insects’ celestial compass and its adaptation to different environments.","tags":null,"title":"Evripidis Gkanias","type":"authors"},{"authors":["Evripidis Gkanias","Barbara Webb"],"categories":null,"content":"","date":1742630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1742630400,"objectID":"b07de81b4cc8256adca8cceae83df655","permalink":"https://evgkanias.github.io/publication/spatiotemporal-computations-in-the-insect-celestial-compass/","publishdate":"2025-03-22T00:00:00Z","relpermalink":"/publication/spatiotemporal-computations-in-the-insect-celestial-compass/","section":"publication","summary":"Insects use the sun for navigation, compensating for its movement throughout the day; a process that remains poorly understood. This study proposes a model of how oscillatory signals of clock neurons could allow insects to transform the sun position into a stable geocentric heading reference.","tags":null,"title":"Spatiotemporal computations in the insect celestial compass","type":"publication"},{"authors":["David Alcer","Nelia Zaiats","Thomas K Jensen","Abbey M Philip","Evripidis Gkanias","Nils Ceberg","Abhijit Das","Vidar Flodgren","Stanley Heinze","Magnus T Borgström","Barbara Webb","Bo W Laursen","Anders Mikkelsen"],"categories":null,"content":"","date":1736841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736841600,"objectID":"a0ae878b1228abd65f06ed200b12bae8","permalink":"https://evgkanias.github.io/publication/integrating-molecular-photoswitch-memory-with-nanoscale-optoelectronics-for-neuromorphic-computing/","publishdate":"2025-01-14T00:00:00Z","relpermalink":"/publication/integrating-molecular-photoswitch-memory-with-nanoscale-optoelectronics-for-neuromorphic-computing/","section":"publication","summary":"Photonic solutions are potentially highly competitive for energy-efficient neuromorphic computing. However, a combination of specialized nanostructures is needed to implement all neuro-biological functionality. Here, we show that donor-acceptor Stenhouse adduct dyes integrated with III-V semiconductor nano-optoelectronics have combined excellent functionality for bio-inspired neural networks. The dye acts as synaptic weights in the optical interconnects, while the nano-optoelectronics provide neuron reception, interpretation and emission of light signals. These dyes can reversibly switch from absorbing to non-absorbing states, using specific wavelength ranges. Together, they show robust and predictable switching, low energy thermal reset and a memory dynamic range from days to sub-seconds that allows both short- and long-term memory operation at natural timescales. Furthermore, as the dyes do not need electrical connections, on-chip integration is simple. We illustrate the functionality using individual nanowire photodiodes as well as arrays. Based on the experimental performance metrics, our on-chip solution is capable of operating an anatomically validated model of the insect brain navigation complex.","tags":null,"title":"Integrating molecular photoswitch memory with nanoscale optoelectronics for neuromorphic computing","type":"publication"},{"authors":null,"categories":null,"content":"PROBLEM Animals use the sun, wind, and other directional cues to guide their behaviors. To orient themselves accurately, they must determine the relative reliability of each cue, and precisely determine, for example, where in the sky the sun is located. Many insects, however, are unable to maintain perfect gaze stabilization, i.e., they cannot fixate a stable point on their retinas while moving on the ground. This is because their heads—and thus their eyes—will move over large angles of perception as they transverse the world. These perturbations will be even more dramatic when moving over uneven terrain. In theory, this should provide these navigators with highly noisy sensory readings of their directional cues. Still, they navigate with impressive precision. The inability to stabilize the gaze is a problem not only for biological systems—that seem to have found ways to mitigate its consequences—but also in the fields of robotics, where agents often need to deal with noisy input and unpredictable postural deviations.\nSOLUTION To direct the highly precise steering that we still observe in animals, the neural computations that support these behaviors must be highly robust to self-motion and externally induced disturbances to the directional cues. Dung beetles are perfect organisms in which to address the solutions that have evolved to process noisy visual information to inform accurate responses for three reasons:\nThey orient in some of the most visually challenging habitats on earth. They exhibit a singular and extremely robust orientation behaviour. A large body and brain size make them ideal for neurophysiological experiments and for carrying miniturized electronic equipment. My 25 years of experience with this unique biological system now allows us to apply a unique combination of 3D-positional recordings, behavioral analyses, electrophysiological recordings and computational models of visual input and neural circuitry to reveal the insects’ solutions to mitigate noise. The formulated models will be evaluated on a robotic platform.\nPROJECT AIM The overarching goal of this cross-disciplinary project is to reveal the solutions, honed by millions of years of evolution, that insects employ to compensate for the sensory and computational challenges imposed by navigational perturbations and noisy sensory input. In doing so, I expect to make scientific advances within animal navigation, as well as the fields of sensing, robotics, cognition, perception, and artificial intelligence.\n","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"d984397311b00f48200b3f0e37e63ae9","permalink":"https://evgkanias.github.io/project/adaptive-compass/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/project/adaptive-compass/","section":"project","summary":"A unique combination of 3D-positional recordings, behavioral analyses, electrophysiological recordings, computational models of visual input and neural circuitry to reveal the insects’ solutions to mitigate noise.","tags":["computational model","insect","circuit","celestial compass","navigation","skylight","polarisation","neuroscience","adaptation"],"title":"How noisy information informs accurate responses in natural and artificial systems","type":"project"},{"authors":["Kathrin Pabst","Evripidis Gkanias","Barbara Webb","Uwe Homberg","Dominic Endres"],"categories":null,"content":"","date":1734681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1734681600,"objectID":"6e0c6288cbc73271d3dcf2abf686460f","permalink":"https://evgkanias.github.io/publication/a-computational-model-for-angular-velocity-integration-in-a-locust-heading-circuit/","publishdate":"2024-12-20T00:00:00Z","relpermalink":"/publication/a-computational-model-for-angular-velocity-integration-in-a-locust-heading-circuit/","section":"publication","summary":"Accurate navigation often requires the maintenance of a robust internal estimate of heading relative to external surroundings. We present a model for angular velocity integration in a desert locust heading circuit, applying concepts from early theoretical work on heading circuits in mammals to a novel biological context in insects. In contrast to similar models proposed for the fruit fly, this circuit model uses a single 360° heading direction representation and is updated by neuromodulatory angular velocity inputs. Our computational model was implemented using steady-state firing rate neurons with dynamical synapses. The circuit connectivity was constrained by biological data, and remaining degrees of freedom were optimised with a machine learning approach to yield physiologically plausible neuron activities. We demonstrate that the integration of heading and angular velocity in this circuit is robust to noise. The heading signal can be effectively used as input to an existing insect goal-directed steering circuit, adapted for outbound locomotion in a steady direction that resembles locust migration. Our study supports the possibility that similar computations for orientation may be implemented differently in the neural hardware of the fruit fly and the locust.","tags":null,"title":"A computational model for angular velocity integration in a locust heading circuit","type":"publication"},{"authors":["Evripidis Gkanias","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1722416400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722416400,"objectID":"371057578febd7fce522e510160dc11c","permalink":"https://evgkanias.github.io/talk/time-compensation-in-the-celestial-compass-of-insects/","publishdate":"2024-07-26T09:00:00Z","relpermalink":"/talk/time-compensation-in-the-celestial-compass-of-insects/","section":"event","summary":"We propose a mechanism that can transform the sun's position into a compass that points north.","tags":["celestial compass","time compensation","solar ephemeris","computational model","central place foraging","migration","insect","central complex","clock neurons","navigation","neuroscience","fruit flies","monarch butterflies","Bogong moths","dragonflies"],"title":"Time compensation in the celestial compass of insects","type":"event"},{"authors":["Evripidis Gkanias","Robert Mitchell","Jan Stankiewicz","Sadeque R. Khan","Srinjoy Mitra","Barbara Webb"],"categories":null,"content":"","date":1701266400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701266400,"objectID":"2c3c0a87121c3a2990a3d7a1391d5b12","permalink":"https://evgkanias.github.io/publication/celestial-compass-design-mimics-the-fan-like-polarisation-filter-array-of-insect-eyes/","publishdate":"2023-10-07T00:00:00Z","relpermalink":"/publication/celestial-compass-design-mimics-the-fan-like-polarisation-filter-array-of-insect-eyes/","section":"publication","summary":"Editor's Choice Paper 2023. Hardware prototype of the model using a ring of UV-sensitive photodiode pairs, and test it under cloudy and occluded skies.","tags":["bio-inspired robotics","celestial compass","central complex","computer vision","navigation","polarisation","skylight","computational model","insect"],"title":"Celestial compass sensor mimics the insect eye for navigation under cloudy and occluded skies","type":"publication"},{"authors":["Evripidis Gkanias","Robert Mitchell","Barbara Webb"],"categories":null,"content":"","date":1692700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692700800,"objectID":"1616de4bae76c7585a16c385425a47d2","permalink":"https://evgkanias.github.io/talk/multimodal-skylight-information-improves-the-estimation-of-the-celestial-compass-insights-from-a-hardware-implementation/","publishdate":"2023-08-02T20:00:25.315Z","relpermalink":"/talk/multimodal-skylight-information-improves-the-estimation-of-the-celestial-compass-insights-from-a-hardware-implementation/","section":"event","summary":"The most common problem in navigation is the accumulation of directional errors. Insects solve this problem using a neural compass   based on external celestial cues. In previous work, we hypothesised a computational model of a neural circuit that converted polarised skylight to compass direction. The model was constrained by the insect’s sensor array and operated under a simulated sky. Using only the polarisation pattern of the sky, it could accurately estimate the solar azimuth, elevation, and the confidence of its estimations.\n\nIn order to estimate the performance of this model in real-sky conditions, we built a compass sensor prototype with eight polarisation sensitive units arranged on a ring (simplifying the dome structure of the original model) and elevated by 45 degree. Following the model’s description, each unit integrated the input of two photodiodes to separate the light intensity from the degree of polarization. The photodiodes were sensitive to ultraviolet (UV) light and placed under linear polarisation filters, which were aligned with the units’ meridian and oriented perpendicularly to each other. We collected the responses of the photodiodes while rotating the compass sensor under different sky conditions: clear or overcast sky, under trees or solid canopies, and at different times of the day. The compass model used these to estimate the heading direction with respect to the sun. Finally, we estimated the heading direction using different modalities of light (intensity or degree of polarisation) and compared their performance.\n\nLight intensity seemed particularly useful as a cue under clear sky conditions and when the sun was clearly visible by the sensor. The degree of polarisation made the estimations of the compass more accurate when the sun was hidden, under thin clouds or tree covers. Simple retinotopic integration of the two modalities outperformed both the intensity- and polarisation-only models and utilised the advantages of both. Our results suggested that the compass design and computational model could successfully predict the location of the sun in most solar elevations, cloud covers, occlusions and atmospheric conditions. Also, this hardware implementation allowed for interesting predictions on the different stages of the polarisation pathway in the insect brain.","tags":["bio-inspired robotics","central complex","computational model","computer vision","insect","navigation","celestial compass","polarisation","skylight"],"title":"Multimodal skylight information improves the estimation of the celestial compass: insights from a hardware implementation","type":"event"},{"authors":["Evripidis Gkanias","Barbara Webb"],"categories":null,"content":"","date":1685282400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685282400,"objectID":"b48c4a2c60d790f89702a8b5c148da02","permalink":"https://evgkanias.github.io/talk/memory-dynamics-in-drosophilas-mushroom-body-a-computational-view/","publishdate":"2023-06-03T20:00:00Z","relpermalink":"/talk/memory-dynamics-in-drosophilas-mushroom-body-a-computational-view/","section":"event","summary":"In this talk I present how our anatomically accurate incentive circuit predicts the responses of mushroom body neurons from the fruit fly brain and how they can be used to create similar behaviour to the one observed in the animals.","tags":["circuit","computational model","fruitfly","insect","memory","mushroom body","neuroscience","olfactory learning"],"title":"Memory dynamics in Drosophila's mushroom body: a computational view","type":"event"},{"authors":["Evripidis Gkanias","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1665526200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665526200,"objectID":"375dc7e8d8ce41bba5b8c15f8ea496d0","permalink":"https://evgkanias.github.io/talk/how-the-fan-shaped-body-can-integrate-differential-familiarity-for-route-following-in-desert-ants/","publishdate":"2022-10-09T18:00:00Z","relpermalink":"/talk/how-the-fan-shaped-body-can-integrate-differential-familiarity-for-route-following-in-desert-ants/","section":"event","summary":"We suggest a mechanism that integrates the allocentric velocity of the animal (estimated by the fan-shaped body) and the scene familiarity (estimated by the mushroom body) to a target velocity that drives the behaviour of the animal.","tags":["desert ant","behaviour","central complex","circuit","computational model","fruitfly","insect","memory","mushroom body","navigation","visual place recognition"],"title":"How the fan-shaped body can integrate differential familiarity for route following in desert ants","type":"event"},{"authors":["Evripidis Gkanias","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1658761200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658761200,"objectID":"9ec251f7672b82080f1555890841921b","permalink":"https://evgkanias.github.io/talk/how-could-the-mushroom-body-and-central-complex-combine-for-visual-homing-in-insects/","publishdate":"2022-05-23T14:00:00Z","relpermalink":"/talk/how-could-the-mushroom-body-and-central-complex-combine-for-visual-homing-in-insects/","section":"event","summary":"We test the performance of the incentive circuit in the visual place recognition task and suggest that the familiarity must increase along a familiar route. Additionally, PCA whitenning and combinatorial encoding techniques enhanced the separability of visual scenes. The familiarity could be used as input to the central complex for visual homing.","tags":["desert ant","central complex","circuit","computational model","fruitfly","insect","memory","mushroom body","navigation","neuroscience"],"title":"How could the mushroom body and central complex combine for visual homing in insects?","type":"event"},{"authors":null,"categories":null,"content":"The goal of the project is to develop nanophotonic on-chip devices for integrated sensing and neural computation, inspired by the insect brain. This will uniquely combine four lines of research:\nProgress in understanding insect neurobiology that provides proven circuit designs to solve significant problems such as autonomous navigation; Advanced III-V semiconductor nanowire technology that exploits light to obtain a large number of interconnects with extremely low power consumption; Optically efficient stable molecular dyes that can be used for novel memory components; Circuit technology developed for quantum computing. As proof of concept, we target the complete pathway from polarised light sensing in the insect eye to the internal compass and memory circuits by which this information is integrated in a continuous accurate estimate of location.\nThe project is funded by the EC in the Horizon Europe programme (GA 101046790). The project started on 1st of April 2022 and run for four years.\nThe project is a collaboration of research groups at Lund University, the University of Copenhagen, the University of Edinburgh, and University of Groningen.\n","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"9159b5ed5f79169f833cdfc4d97f243b","permalink":"https://evgkanias.github.io/project/insect-neuro-nano/","publishdate":"2022-06-01T00:00:00Z","relpermalink":"/project/insect-neuro-nano/","section":"project","summary":"The goal of the project is to develop nanophotonic on-chip devices for integrated sensing and neural computation, inspired by the insect brain.","tags":["bio-inspired robotics","computational model","insect","circuit","celestial compass","central complex","navigation","skylight","polarisation","neuroscience","nanotechnology","molecular dyes","memory"],"title":"Insect-brain inspired neuromorphic nanophotonics","type":"project"},{"authors":["Evripidis Gkanias","Li Yan McCurdy","Michael N. Nitabach","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1647721800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647721800,"objectID":"f88f216e29bdcd370fb24dd84bf2bbe0","permalink":"https://evgkanias.github.io/talk/an-anatomically-accurate-circuit-for-short-and-long-term-motivational-learning-in-fruit-flies/","publishdate":"2022-03-15T14:00:00Z","relpermalink":"/talk/an-anatomically-accurate-circuit-for-short-and-long-term-motivational-learning-in-fruit-flies/","section":"event","summary":"We present how our novel dopaminergic learning rule and the incentive circuit predict the responses of mushroom body neurons from the fruit fly brain and create similar behaviour to the one observed in the animals.","tags":["circuit","computational model","fruitfly","insect","memory","mushroom body","neuroscience","olfactory learning"],"title":"An anatomically accurate circuit for short- and long-term motivational learning in fruit flies","type":"event"},{"authors":["Evripidis Gkanias","Li Yan McCurdy","Michael N. Nitabach","Barbara Webb"],"categories":null,"content":"","date":1646748000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646748000,"objectID":"c3549c4794c198fdb93ec1336befa92c","permalink":"https://evgkanias.github.io/publication/an-incentive-circuit-memory-dynamics-in-the-mushroom-body-of-drosophila-melanogaster/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/publication/an-incentive-circuit-memory-dynamics-in-the-mushroom-body-of-drosophila-melanogaster/","section":"publication","summary":"Modelling differential roles for identified dopaminergic and output neurons of the fruit-fly mushroom bodies combined with a novel dopaminergic plasticity rule explains neural and behavioural phenomena in olfactory learning tasks.","tags":["fruitfly","insect","behaviour","memory","mushroom body","computational model","olfactory learning","neuroscience","circuit"],"title":"An incentive circuit for memory dynamics in the mushroom body of Drosophila melanogaster","type":"publication"},{"authors":["Evripidis Gkanias","Li Yan McCurdy","Michael N. Nitabach","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1632330000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632330000,"objectID":"130dccdbcaeb8b06275beaa1f3986fde","permalink":"https://evgkanias.github.io/talk/the-incentive-circuit-of-the-fruit-fly-brain-a-computational-perspective/","publishdate":"2021-09-23T20:00:00Z","relpermalink":"/talk/the-incentive-circuit-of-the-fruit-fly-brain-a-computational-perspective/","section":"event","summary":"In this poster we show how our anatomically accurate incentive circuit predicts the responses of mushroom body neurons from the fruit fly brain and how they can be used to create similar behaviour to the one observed in the animals.","tags":["circuit","computational model","fruitfly","insect","memory","mushroom body","neuroscience","olfactory learning"],"title":"The incentive circuit of the fruit fly brain: a computational perspective","type":"event"},{"authors":["Evripidis Gkanias","Li Yan McCurdy","Michael N. Nitabach","Barbara Webb"],"categories":null,"content":"","date":1622561520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622561520,"objectID":"dccd15c832d5d52bfc9130e19d5d61ac","permalink":"https://evgkanias.github.io/talk/how-flies-acquire-forget-and-assimilate-memories-a-computational-perspective/","publishdate":"2021-06-02T23:00:00Z","relpermalink":"/talk/how-flies-acquire-forget-and-assimilate-memories-a-computational-perspective/","section":"event","summary":"In this talk we present our recent work building an anatomically accurate neural circuit that allow memory dynamics in the fruit-fly brain.","tags":["circuit","computational model","fruitfly","insect","memory","mushroom body","neuroscience","olfactory learning"],"title":"How flies acquire, forget and assimilate memories: a computational perspective","type":"event"},{"authors":["Sebastian Schwarz","Leo Clement","Evripidis Gkanias","Antoine Wystrach"],"categories":null,"content":"","date":1592658050,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592658050,"objectID":"a08f1a3b59e09257ff7bfaebf3fe142a","permalink":"https://evgkanias.github.io/publication/how-do-backward-walking-ants-cataglyphis-velox-cope-with-navigational-uncertainty/","publishdate":"2020-06-20T13:00:50.337Z","relpermalink":"/publication/how-do-backward-walking-ants-cataglyphis-velox-cope-with-navigational-uncertainty/","section":"publication","summary":"* Backward-walking ants can steer using learnt terrestrial visual cues.\n* Steering does not require forward body alignment.\n* Steering may be based on the integration of attractive and repulsive views.\n* Peeking behaviour is triggered in periods of low directional certainty.\n* Directional certainty is built on multiple sources of current and past information.","tags":["desert ant","behaviour","backward movement","navigation","peeking","uncertainty","visual place recognition","memory"],"title":"How do backward-walking ants (Cataglyphis velox) cope with navigational uncertainty?","type":"publication"},{"authors":["Evripidis Gkanias","Benjamin Risse","Michael Mangan","Barbara Webb"],"categories":null,"content":"","date":1574178625,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574178625,"objectID":"135c83e051d99f5d2eaba467253cd88a","permalink":"https://evgkanias.github.io/talk/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","publishdate":"2019-11-19T20:00:25.315Z","relpermalink":"/talk/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","section":"event","summary":"In this talk we present our recent findings of the desert-ants' celestial compass which uses the polarised-light pattern in the sky to estimate its heading direction.","tags":["desert ant","behaviour","central complex","circuit","computational model","computer vision","insect","navigation","celestial compass","polarisation","skylight"],"title":"From skylight input to behavioural output: a computational model of the insect polarised light compass","type":"event"},{"authors":["Evripidis Gkanias","Alina Scaria","Natalie A. Vladis","Benjamin Risse","Michael Mangan","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1565280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565280000,"objectID":"1840842aaf6c943537717a8dc3f2b02f","permalink":"https://evgkanias.github.io/talk/robustness-of-a-model-of-the-insects-celestial-compass-in-realistic-conditions/","publishdate":"2019-08-20T20:00:25.315Z","relpermalink":"/talk/robustness-of-a-model-of-the-insects-celestial-compass-in-realistic-conditions/","section":"event","summary":"The most common problem in navigation is the accumulation of\ndirectional errors. Insects solve this problem by using a neural\ncompass based on external celestial. In our recent work we hypothesise\na computational model that explains how a neural circuit could convert\npolarised skylight to a compass output, given realistic constraints based\non the insect's sensor array operating under natural skylight. This model\ncan estimate the solar azimuth and elevation, as well as the certainty of\nits estimations, using only the polarisation pattern of the sky. It can\ncompensate for head tilt and the change of the sun position over time,\nthus reducing errors that would arise in uneven terrains and during long\njourneys.\n\nIn this work, we demonstrate the robustness of the sensor in\nrealistic scenarios and test whether it can be efficiently used as input to\nan existing neural model of insect path integration. More specifically, we\ndesigned a set of experiments for our model that allow the validation of\nits performance in the path integration task. We simulate canopy-like\ndisturbance, covering parts of the sky and measuring the error of the sensor.\nDifferent terrain complexity is emulated by changing the maximum and minimum\naltitude of a predefined uneven terrain, producing up to 52 degrees of\ntilting angle (1m altitude variance).\n\nOur results show that, both in a\nsimulation and a prototype of the sensor (see inset in figure), the error\nof the sensor is proportional to the disturbance level. However, this did\nnot significantly affect the performance of a simulated insect integrating\nits path. We observed that when the experimental set-up is realistic enough,\nthe sensor's errors tend to be systematic. This means that errors occurring\ndue to sky disturbance and tilting of the ground during the inward path tend\nto cancel out the respective errors in the outward one. We suggest the sensor\nlayout and subsequent neural processing has evolved such that the animal's\ninteraction with its environment tends to compensate for disturbances,\nreducing the computational complexity of the compass processing required for\nrobust path integration.","tags":["desert ant","central complex","computational model","computer vision","insect","navigation","celestial compass","polarisation","skylight"],"title":"Robustness of a model of the insects' celestial compass in realistic conditions","type":"event"},{"authors":["Evripidis Gkanias","Benjamin Risse","Michael Mangan","Barbara Webb"],"categories":null,"content":"","date":1563454825,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563454825,"objectID":"3ef88ee271428c3a9c266ee6d2de86e5","permalink":"https://evgkanias.github.io/publication/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","publishdate":"2019-07-18T13:00:25.345Z","relpermalink":"/publication/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","section":"publication","summary":"We propose a new hypothesis for how insects process polarised skylight to extract global orientation information that can be used for accurate path integration. Our model solves the problem of solar-antisolar meridian ambiguity by using a biologically constrained sensor array, and includes methods to deal with tilt and time, providing a complete insect celestial compass output. We analyse the performance of the model using a realistic sky simulation and various forms of disturbances, and compare the results to both engineering approaches and biological data.","tags":["desert ant","behaviour","navigation","computer vision","polarisation","skylight","path integration","central complex","circadian mechanism","celestial compass","circuit","computational model","insect","neuroscience"],"title":"From skylight input to behavioural output: a computational model of the insect polarised light compass","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://evgkanias.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Evripidis Gkanias","Kostantinos Lagogannis","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1539007200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539007200,"objectID":"0ac9680dc812ee992b9381713aeba9fb","permalink":"https://evgkanias.github.io/talk/imitating-the-drosophila-larval-learning-behaviour-on-a-robot/","publishdate":"2018-10-09T20:00:25.315Z","relpermalink":"/talk/imitating-the-drosophila-larval-learning-behaviour-on-a-robot/","section":"event","summary":" Your web browser doesn't have a PDF plugin. Instead you can click here to download the PDF file. ","tags":["behaviour","bio-inspired robotics","circuit","computational model","fruitfly","insect","larvae","memory","mushroom body","olfactory learning"],"title":"Imitating the Drosophila Larval Learning Behaviour on a Robot","type":"event"},{"authors":null,"categories":null,"content":"Historically, reinforcement learning is a branch of machine learning founded on observations of how animals learn. This involved collaboration between the fields of biology and artificial intelligence that was beneficial to both fields, creating smarter artificial agents and improving the understanding of how biological systems function. The evolution of reinforcement learning during the past few years was rapid but substantially diverged from providing insights into how biological systems work, opening a gap between reinforcement learning and biology. In an attempt to close this gap, this thesis studied the insect neuroethology of reinforcement learning, that is, the neural circuits that underlie reinforcement-learning-related behaviours in insects. The goal was to extract a biologically plausible plasticity function from insect-neuronal data, use this to explain biological findings and compare it to more standard reinforcement learning models. Consequently, a novel dopaminergic plasticity rule was developed to approximate the function of dopamine as the plasticity mechanism between neurons in the insect brain. This allowed a range of observed learning phenomena to happen in parallel, like memory depression, potentiation, recovery, and saturation. In addition, by using anatomical data of connections between neurons in the mushroom body neuropils of the insect brain, the neural incentive circuit of dopaminergic and output neurons was also explored. This, together with the dopaminergic plasticity rule, allowed for dynamic collaboration amongst parallel memory functions, such as acquisition, transfer, and forgetting. When tested on olfactory conditioning paradigms, the model reproduced the observed changes in the activity of the identified neurons in fruit flies. It also replicated the observed behaviour of the animals and it allowed for flexible behavioural control. Inspired by the visual navigation system of desert ants, the model was further challenged in the visual place recognition task. Although a relatively simple encoding of the olfactory information was sufficient to explain odour learning, a more sophisticated encoding of the visual input was required to increase the separability among the visual inputs and enable visual place recognition. Signal whitening and sparse combinatorial encoding were sufficient to boost the performance of the system in this task. The incentive circuit enabled the encoding of increasing familiarity along a known route, which dropped proportionally to the distance of the animal from that route. Finally, the proposed model was challenged in delayed reinforcement tasks, suggesting that it might take the role of an adaptive critic in the context of reinforcement learning.\nThis is an embedded Microsoft Office presentation, powered by Office Online. ","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"070d51a28892f81411bee8389f825d6d","permalink":"https://evgkanias.github.io/project/phd-thesis/","publishdate":"2018-09-01T00:00:00Z","relpermalink":"/project/phd-thesis/","section":"project","summary":"Thesis - Doctor of Philosophy. I inversigated how insects form associative memories in their mushroom bodies and how this impacts their olfactory learning, visual navigation, and time-delayed reinforcements tasks.","tags":["bio-inspired robotics","computer vision","olfactory learning","computational model","insect","desert ant","fruitfly","circuit","memory","mushroom body","central complex","navigation","neuroscience","visual place recognition"],"title":"Insect neuroethology of reinforcement learning","type":"project"},{"authors":["Daniela Pacella","Evripidis Gkanias","Michael Mangan","Barbara Webb"],"categories":null,"content":" Your web browser doesn\u0026#39;t have a PDF plugin. Instead you can click here to download the PDF file. ","date":1532253600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532253600,"objectID":"703a8b43f16c6176c862f878b19ccd52","permalink":"https://evgkanias.github.io/talk/neural-models-of-ant-navigation-in-a-realistic-3d-world/","publishdate":"2018-08-20T20:00:25.315Z","relpermalink":"/talk/neural-models-of-ant-navigation-in-a-realistic-3d-world/","section":"event","summary":" Your web browser doesn't have a PDF plugin. Instead you can click here to download the PDF file. ","tags":["mushroom body","computer vision","computer simulation","desert ant","circuit","computational model","insect","memory","navigation","polarisation","visual place recognition"],"title":"Neural models of ant navigation in a realistic 3D world","type":"event"},{"authors":["Evripidis Gkanias","Theodoros Stouraitis","Jan M. Hemmi","Barbara Webb"],"categories":null,"content":"","date":1501149609,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501149609,"objectID":"8cde1aace5a0a8a96b4d872bb4775ba6","permalink":"https://evgkanias.github.io/talk/predator-evasion-by-a-robocrab/","publishdate":"2017-07-29T16:20:09.572Z","relpermalink":"/talk/predator-evasion-by-a-robocrab/","section":"event","summary":"We describe the first robot designed to emulate the specific perceptual and motor capabilities of the fiddler crab. An omnidirectional robot platform uses onboard computation to process images from a 360 degrees camera view, filtering them through a biological model of the crab’s ommatidia layout, extracting potential ‘predator’ cues, and executing an evasion response that also depends on contextual information. We show that, as for real crabs, multiple cues are needed for effective escape in different predator-prey scenarios.","tags":["bio-inspired robotics","computational model","computer vision","fiddler crab","behaviour"],"title":"Predator Evasion by a Robocrab","type":"event"},{"authors":["Theodoros Stouraitis","Evripidis Gkanias","Barbara Webb"],"categories":null,"content":"","date":1500210051,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500210051,"objectID":"185aff324540bc7d66fa9b65972dcee4","permalink":"https://evgkanias.github.io/publication/predator-evasion-by-a-robocrab/","publishdate":"2017-07-16T13:00:51.237Z","relpermalink":"/publication/predator-evasion-by-a-robocrab/","section":"publication","summary":"We describe the first robot designed to emulate the specific perceptual and motor capabilities of the fiddler crab. An omnidirectional robot platform uses onboard computation to process images from a 360 degrees camera view, filtering them through a biological model of the crab’s ommatidia layout, extracting potential ‘predator’ cues, and executing an evasion response that also depends on contextual information. We show that, as for real crabs, multiple cues are needed for effective escape in different predator-prey scenarios.","tags":["bio-inspired robotics","computational model","computer vision","fiddler crab","behaviour"],"title":"Predator Evasion by a Robocrab","type":"publication"},{"authors":null,"categories":null,"content":"Outdoor navigation in natural environments remains a challenge for robotics. Recent breakthroughs in robot navigation have been dependent on specific sensor technologies, such as laser depth sensors and GPS, and advanced image processing. The ability of animals such as ants to navigate effectively without such power- and computation- hungry systems are a proof of principle that alternative cheaper approaches are viable. Ants also have specialised sensing, with a peripheral visual system that has evolved to be sensitive to crucial cues for navigation. Specifically, they make use of non-visible (to humans) light cues in the form of ultraviolet (UV) and polarised light detection. UV detection allows the important signal of the horizon shape against the sky to be easily distinguished. Polarised light detection provides an external compass cue of heading relative to the sun direction, even when only a small portion of the sky is visible.\nWe propose to build a sensory system that gathers the full range of light cues available to the ant, in its natural ecological situation, and to analyse the information contained in this signal. We will also analyse how the specific sensor layout (ommatidia array), peripheral receptor characteristics, and the motor behaviour of the ant may contribute to extracting salient information. The data will form a test-bed for comparison of algorithmic and neural models of the processing that underlies the navigation capabilities of the ant. To date, these cues have been considered separately but we believe the navigational success of this system depends on the specific combination. For example, the directional information in the polarised sky may form an important part of visual memories; and UV information may contribute to disambiguation of the polarisation pattern and the robustness of this information under different cloud conditions.\nThere has been a substantial increase in the last few years in research into insect neural pathways involved in processing these cues which has yet to be exploited in robot models. In particular there has been breakthrough work on the central brain mechanisms involved in decoding polarised light to obtain heading direction. There is also a rapidly increasing understanding of the circuits involved in learning, a key component of navigation capabilities.\n","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488326400,"objectID":"bc8680a19f164de7acddb81f1ab79bb9","permalink":"https://evgkanias.github.io/project/invisible-cues/","publishdate":"2017-03-01T00:00:00Z","relpermalink":"/project/invisible-cues/","section":"project","summary":"Design a sensor that transforms skylight into a compass direction.","tags":["bio-inspired robotics","computational model","insect","desert ant","circuit","celestial compass","central complex","computer vision","navigation","skylight","polarisation","behaviour"],"title":"Exploiting invisible cues for robot navigation in complex natural environments","type":"project"},{"authors":null,"categories":null,"content":"Biology provides the inspiration for a vision of small low-power devices that are able to learn rapidly and autonomously about environmental contingencies, enabling prediction and adaptive anticipatory action. Larval Drosophila have fewer than 10,000 neurons, yet express a variety of complex orientation and learning behaviours, including non-trivial anticipatory actions requiring context-dependent evaluation of the value of learned cues. Current computational learning theory cannot fully account for or replicate these capacities. We aim to develop a new foundation for understanding natural learning by developing a complete multilevel model of learning in larvae.\nOur aims are:\nto analyse at a fine scale how larval olfactory behaviour is controlled and altered by associative conditioning, linked to agent-based models that ground learning capabilities in ongoing sensorimotor control; to build one-to-one computational neural models that can be validated by exploiting the recent expansion of the Drosophila neurogenetic toolkit to gain unprecedented ability to characterise and manipulate neural circuits during unconstrained behaviour; to derive from these models novel, generalisable algorithms and circuit architectures that can be used to enhance the learning and anticipatory capabilities of machines. ","date":1472688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472688000,"objectID":"ce2a9d390cfa7b30baf7cd689ab3d1d7","permalink":"https://evgkanias.github.io/project/minimal/","publishdate":"2016-09-01T00:00:00Z","relpermalink":"/project/minimal/","section":"project","summary":"We develop a new foundation for understanding natural learning by developing a complete multilevel model of learning in larvae","tags":["bio-inspired robotics","computational model","insect","fruitfly","larvae","circuit","memory","mushroom body","neuroscience","olfactory learning","behaviour"],"title":"Miniature insect model for active learning (minimal)","type":"project"},{"authors":null,"categories":null,"content":"Analysing the behaviour of animals and studying their brain structure is a common way to create bio-inspired artificial intelligence methods. Fiddler crabs are animals with specific limitations on their sensors that have a great ability of evading on the presence of potential predators. In this project we study these animals with respect to the physiology of their unique sensor – their vision – and their evading manoeuvres, in order to create a machine learning model, which imitates this interesting behaviour. More specifically, we propose a semi-supervised architecture of neural network, inspired by the structure of fiddler crabs’ brain and their evasion behaviour’s feedback loops. We combine location specific visual units and LSTM recurrent units in order to build a model capable to adapt this behaviour. We trained our model using a data-set we created using data from experiments done with living crabs in their habitat. Comparing our statistical results of our model’s behaviour with the ones of the original crabs behaviour we show that this model captured some key features of this behaviour as well as it seems to behave quite realistic in the simulations. Therefore, we show that it is reasonable to consider machine learning models as potential solutions in animal behaviour adaptation problems.\n","date":1454284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454284800,"objectID":"bb165e92cefdd0a8eb932e0b931d1480","permalink":"https://evgkanias.github.io/project/msc-thesis/","publishdate":"2016-02-01T00:00:00Z","relpermalink":"/project/msc-thesis/","section":"project","summary":"Disertation - Master of Science. We create a semi-supervised structure of neural network, inspired by the physiology of neurons in fiddler crabs, and train it to adapt the evasion behaviour of fiddler crabs on potential predators, solving a complicated visuomotor problem (developed in Python using the Theano/Tensorflow-based ‘keras’ library","tags":["computer vision","bio-inspired robotics","computational model","fiddler crab","circuit","deep learning","machine learning","LSTM","behaviour"],"title":"Robocrab: data-driven adaptation of the evation behaviour in fiddler crabs","type":"project"},{"authors":null,"categories":null,"content":"FI-STAR will establish early trials in the Health Care domain building on Future Internet (FI) technology leveraging on the outcomes of FI-PPP Phase 1.\nIt will become self-sufficient after the end of the project and will continue on a sustainable business model by several partners. In order to meet the requirements of a global Health industry FI-STAR will use a fundamentally different, “reverse” cloud approach that is. It will bring the software to the data, rather than bringing the data to the software. FI-STAR will create a robust framework based of the “software to data” paradigm.\nA sustainable value chain following the life cycle of the Generic Enablers (GEs) will enable FI-STAR to grow beyond the lifetime of the project. FI-STAR will build a vertical community in order to create a sustainable ecosystem for all user groups in the global Health care and adjacent markets based on FI-PPP specifications.\nFI-STAR will deploy and execute 7 early trials across Europe, serving more than 4 million people. Through the trials FI-STAR will validate the FI-PPP core platform concept by using GEs to build its framework and will introduce ultra-light interactive applications for user functionality.\nIt will pro-actively engage with the FI-PPP to propose specifications and standards.FI-STAR will use the latest digital media technology for community building and will proactively prepare for Phase 3 through targeted elicitation of new partners using open calls.\nFinally, FI-STAR will collaborate with other FI-PPP projects, through the mechanisms in place, by actively interacting with all necessary bodies. FI-STAR is a unique opportunity for implementing Future Internet Private-Public Partnership in the Health Care domain, by offering to the community standardized and certified software including a safe, secure and resilient platform, taking advantage of all Cloud Computing benefits and guaranteeing the protection of sensitive and personal data travelling in Public Clouds.\n","date":1441029600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441029600,"objectID":"de5f460c5241ea6e388e640b37ad9924","permalink":"https://evgkanias.github.io/project/fi-star/","publishdate":"2015-08-31T14:00:00Z","relpermalink":"/project/fi-star/","section":"project","summary":"FI-STAR will establish early trials in the Health Care domain building on Future Internet (FI) technology leveraging on the outcomes of FI-PPP Phase 1.","tags":["machine learning","biomechanics","engineering","evaluation","human motion tracking","Microsoft kinect","Vicon","computer vision"],"title":"FI-STAR","type":"project"},{"authors":null,"categories":null,"content":"The RePlay project has as its goal the development of a technology platform that shall provide access and interpretation of digital content for Traditional Sports and Games (TSG). It will enable multiple modes of training, coaching and knowledge sharing that will contribute to the increased participation and preservation of traditional sport in the future. This will be achieved by developing a base technology and methodologies for the digitisation of the art and forms of play of a set of representative sports. In the case of RePlay, this will be field based Gaelic team sports and Basque individual/doubles ball and court sports. The fundamental structure of these sports is extensible to a vast majority of traditional minority sports and mainstream sports.\nRePlay will consist of the design and implementation of a platform for the capture, annotation, indexing and provision of 3D sports content. It will include the analysis and specification of methodologies and ideal cost-effective hardware solutions for the extension of the project to other sports. The project will focus on the use of existing and near future 3D motion capture hardware. The project does not include the development of any hardware as an objective, as the market is already addressing this. It shall instead focus on the creation of the knowledge and underlying software tools that will provide a low-cost entry point to other TSG associations.\nRePlay will focus on the analysis, capture and modelling of the basic styles and techniques of play common to all participants or the “Local Hero” using low-cost capture techniques. However, RePlay will also use advanced professional grade capture techniques on “National Heroes”. A national hero, or a recognised elite player, develops their sporting prowess to an extent that is unique. This presents Intangible Cultural Heritage to be preserved, an opportunity to allow the young to try to learn and emulate their heroes, and a scientific opportunity to compare and analyse the evolution in the changes of styles of play over time. RePlay will also include work on retrospective analysis of sports via video content.\n","date":1441029600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441029600,"objectID":"0930f6f881f05e1fa6b49e0d31e0da6c","permalink":"https://evgkanias.github.io/project/replay/","publishdate":"2015-08-31T14:00:00Z","relpermalink":"/project/replay/","section":"project","summary":"Digitally capturing unique skills involved in European Traditional Sports and Games. We develope a system that allows 3D reconstruction of a human, caputed by multiple sensors, and analyse their motion with respect to some ground truth.","tags":["machine learning","biomechanics","engineering","evaluation","human motion tracking","Microsoft kinect","Vicon","computer vision"],"title":"Replay","type":"project"},{"authors":null,"categories":null,"content":"Many scientists, who specialize in supervised learning, are interested in multi-label data for two main reasons. First of all, this type of data arising at a variety of applications such as semantic indexing of documents, music and video, protein function prediction, medical diagnosis, drug discovery and search engine queries clustering. Secondly, multi-label data perform interesting research challenges like the use of correlations between labels and scaling to a large number of labels.\nIn multi-label data, every subject of interest is characterized by one or more labels from a label set and the purpose is not a simple classification of an instance, but a label ranking for their relevance to the subject or a bipartition of them to these that are relevant and those which are not (multi-label classification). In this project, we investigate this field and we apply a deep learning method, inspired by the theory that explains how the brain recognizes patterns. Technology companies are reporting startling gains in fields as diverse as computer vision, speech recognition and the identification of promising new molecules for designing drugs.\nWe present a fairly recent kind of neural network, the deep belief network, which handles multi-label data without transforming them before or after the training. This transformation is undesirable, because it causes the dataset to be bigger. Our aim is to build a model that can handle multi-label data using deep learning techniques. In this project, we showed that these techniques – specifically the deep learning using belief networks – have better results in the most of the encountered subjects of interest\n","date":1359676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1359676800,"objectID":"7693d5d0f7bea749671c6d13552fe5e5","permalink":"https://evgkanias.github.io/project/bsc-thesis/","publishdate":"2013-02-01T00:00:00Z","relpermalink":"/project/bsc-thesis/","section":"project","summary":"Honours Thesis - Bachelor of Science. We extended a Java library implementing Restricted Boltzmann Machines and Deep Belief Networks and we used it to examine how they perform in a variety of multi-label data-sets.","tags":["deep learning","machine learning","restricted Boltzmann machines","multi-label data","deep belief networks","big data"],"title":"Deep learning algorithms for multi-label data","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://evgkanias.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]