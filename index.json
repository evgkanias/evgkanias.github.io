[{"authors":null,"categories":null,"content":"\rI am a PhD student in Bio-inspired Autonomous Systems \u0026amp; Neuroscience, supervised by Prof. Barbara Webb at the University of Edinburgh, School of Informatics.\nI am interested in bio-accurate artificial intelligence and information theory. I currently study the underline mechanism of learning in the mushroom bodies of the insects\u0026#39; brain. My main scientific questions are: how do the mushroom bodies embody an adaptive, continuous-updating and robust associative centre through reinforcement learning and what is their role in visual and elemental navigation.\nMy research interests include probabilistic machine learning (and reinforcement learning), neural computation, bioinspired computer vision and multimodal integration.\n  Download my resumé.","date":1636984800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1636984800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a PhD student in Bio-inspired Autonomous Systems \u0026 Neuroscience, supervised by Prof. Barbara Webb at the University of Edinburgh, School of Informatics.\nI am interested in bio-accurate artificial intelligence and information theory.","tags":null,"title":"Evripidis Gkanias","type":"authors"},{"authors":["Evripidis Gkanias","Li Yan McCurdy","Michael N. Nitabach","Barbara Webb"],"categories":null,"content":"","date":1636984800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636984800,"objectID":"09062ed6fba08652c60c851441a85072","permalink":"https://evgkanias.github.io/publication/the-incentive-circuit-memory-dynamics-in-the-mushroom-body-of-drosophila-melanogaster/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/the-incentive-circuit-memory-dynamics-in-the-mushroom-body-of-drosophila-melanogaster/","section":"publication","summary":"Insects adapt their response to stimuli, such as odours, according to their pairing with positive or negative reinforcements, such as sugar or shock. Recent electrophysiological and imaging findings in Drosophila melanogaster allow detailed examination of the neural mechanisms supporting the acquisition, forgetting and assimilation of memories. We propose that this data can be explained by the combination of a dopaminergic plasticity rule that supports a variety of synaptic strength change phenomena, and a circuit structure (derived from neuroanatomy) between dopaminergic and output neurons that creates different roles for specific neurons. Computational modelling shows that this circuit allows for rapid memory acquisition, transfer from short-term to long-term, and exploration/exploitation trade-off. The model can reproduce the observed changes in the activity of each of the identified neurons in conditioning paradigms and can be used for flexible behavioural control.","tags":["fruitfly","memory","mushroom body","computational model","olfactory learning","neuroscience","circuit"],"title":"The incentive circuit: memory dynamics in the mushroom body of Drosophila melanogaster","type":"publication"},{"authors":["Evripidis Gkanias","Li Yan McCurdy","Michael N. Nitabach","Barbara Webb"],"categories":null,"content":" ","date":1632330000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632330000,"objectID":"b6e682b086792a575bc1fefd936bdf7d","permalink":"https://evgkanias.github.io/talk/the-incentive-circuit-of-the-fruit-fly-brain-a-computational-perspective/","publishdate":"2021-09-23T20:00:00Z","relpermalink":"/talk/the-incentive-circuit-of-the-fruit-fly-brain-a-computational-perspective/","section":"event","summary":"In this poster we show how our anatomically accurate incentive circuit predicts the responses of mushroom body neurons from the fruit fly brain and how they can be used to create similar behaviour to the one observed in the animals.","tags":null,"title":"The incentive circuit of the fruit fly brain: a computational perspective","type":"event"},{"authors":["Evripidis Gkanias","Li Yan McCurdy","Michael N. Nitabach","Barbara Webb"],"categories":null,"content":"This is an embedded Microsoft Office presentation, powered by Office Online.\r","date":1622561520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622561520,"objectID":"db24dce1cd24ba7dbfed2f56318e4a22","permalink":"https://evgkanias.github.io/talk/how-flies-acquire-forget-and-assimilate-memories-a-computational-perspective/","publishdate":"2021-06-02T23:00:00Z","relpermalink":"/talk/how-flies-acquire-forget-and-assimilate-memories-a-computational-perspective/","section":"event","summary":"In this talk we present our recent work building an anatomically accurate neural circuit that allow memory dynamics in the fruit-fly brain.","tags":null,"title":"How flies acquire, forget and assimilate memories: a computational perspective","type":"event"},{"authors":["Sebastian Schwarz","Leo Clement","Evripidis Gkanias","Antoine Wystrach"],"categories":null,"content":"","date":1592658050,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592658050,"objectID":"a08f1a3b59e09257ff7bfaebf3fe142a","permalink":"https://evgkanias.github.io/publication/how-do-backward-walking-ants-cataglyphis-velox-cope-with-navigational-uncertainty/","publishdate":"2020-06-20T13:00:50.337Z","relpermalink":"/publication/how-do-backward-walking-ants-cataglyphis-velox-cope-with-navigational-uncertainty/","section":"publication","summary":"* Backward-walking ants can steer using learnt terrestrial visual cues.\n* Steering does not require forward body alignment.\n* Steering may be based on the integration of attractive and repulsive views.\n* Peeking behaviour is triggered in periods of low directional certainty.\n* Directional certainty is built on multiple sources of current and past information.","tags":["ant","backward movement","navigation","peeking","route following","uncertainty","view-based navigation"],"title":"How do backward-walking ants (Cataglyphis velox) cope with navigational uncertainty?","type":"publication"},{"authors":["Evripidis Gkanias","Benjamin Risse","Michael Mangan","Barbara Webb"],"categories":null,"content":"This is an embedded Microsoft Office presentation, powered by Office Online.\r","date":1574178625,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574178625,"objectID":"89a62c24239cb1d08d68bd47ce2f21c4","permalink":"https://evgkanias.github.io/talk/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","publishdate":"2019-11-19T20:00:25.315Z","relpermalink":"/talk/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","section":"event","summary":"In this talk we present our recent findings of the desert-ants' celestial compass which uses the polarised-light pattern in the sky to estimate its heading direction.","tags":null,"title":"From skylight input to behavioural output: a computational model of the insect polarised light compass","type":"event"},{"authors":["Evripidis Gkanias","Alina Scaria","Natalie A. Vladis","Benjamin Risse","Michael Mangan","Barbara Webb"],"categories":null,"content":" ","date":1565280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565280000,"objectID":"702da7fe8792cfa2620776e3c33d8d26","permalink":"https://evgkanias.github.io/talk/robustness-of-a-model-of-the-insects-celestial-compass-in-realistic-conditions/","publishdate":"2019-08-20T20:00:25.315Z","relpermalink":"/talk/robustness-of-a-model-of-the-insects-celestial-compass-in-realistic-conditions/","section":"event","summary":"The most common problem in navigation is the accumulation of\ndirectional errors. Insects solve this problem by using a neural\ncompass based on external celestial. In our recent work we hypothesise\na computational model that explains how a neural circuit could convert\npolarised skylight to a compass output, given realistic constraints based\non the insect's sensor array operating under natural skylight. This model\ncan estimate the solar azimuth and elevation, as well as the certainty of\nits estimations, using only the polarisation pattern of the sky. It can\ncompensate for head tilt and the change of the sun position over time,\nthus reducing errors that would arise in uneven terrains and during long\njourneys.\n\nIn this work, we demonstrate the robustness of the sensor in\nrealistic scenarios and test whether it can be efficiently used as input to\nan existing neural model of insect path integration. More specifically, we\ndesigned a set of experiments for our model that allow the validation of\nits performance in the path integration task. We simulate canopy-like\ndisturbance, covering parts of the sky and measuring the error of the sensor.\nDifferent terrain complexity is emulated by changing the maximum and minimum\naltitude of a predefined uneven terrain, producing up to 52 degrees of\ntilting angle (1m altitude variance).\n\nOur results show that, both in a\nsimulation and a prototype of the sensor (see inset in figure), the error\nof the sensor is proportional to the disturbance level. However, this did\nnot significantly affect the performance of a simulated insect integrating\nits path. We observed that when the experimental set-up is realistic enough,\nthe sensor's errors tend to be systematic. This means that errors occurring\ndue to sky disturbance and tilting of the ground during the inward path tend\nto cancel out the respective errors in the outward one. We suggest the sensor\nlayout and subsequent neural processing has evolved such that the animal's\ninteraction with its environment tends to compensate for disturbances,\nreducing the computational complexity of the compass processing required for\nrobust path integration.","tags":null,"title":"Robustness of a model of the insects' celestial compass in realistic conditions","type":"event"},{"authors":["Evripidis Gkanias","Benjamin Risse","Michael Mangan","Barbara Webb"],"categories":null,"content":"","date":1563454825,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563454825,"objectID":"3ef88ee271428c3a9c266ee6d2de86e5","permalink":"https://evgkanias.github.io/publication/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","publishdate":"2019-07-18T13:00:25.345Z","relpermalink":"/publication/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/","section":"publication","summary":"We propose a new hypothesis for how insects process polarised skylight to extract global orientation information that can be used for accurate path integration. Our model solves the problem of solar-antisolar meridian ambiguity by using a biologically constrained sensor array, and includes methods to deal with tilt and time, providing a complete insect celestial compass output. We analyse the performance of the model using a realistic sky simulation and various forms of disturbances, and compare the results to both engineering approaches and biological data.","tags":["ant","navigation","computer vision","polarisation","skylight","path integration","central complex","circadian mechanism","celestial","compass"],"title":"From skylight input to behavioural output: a computational model of the insect polarised light compass","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34;\rif porridge == \u0026#34;blueberry\u0026#34;:\rprint(\u0026#34;Eating...\u0026#34;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne \r**Two** \rThree \r A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}}\r{{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}\r  Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://evgkanias.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Evripidis Gkanias","Kostantinos Lagogannis","Barbara Webb"],"categories":null,"content":" ","date":1539007200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539007200,"objectID":"3dfec14f9a631d49f4ba7918ac7ce95b","permalink":"https://evgkanias.github.io/talk/imitating-the-drosophila-larval-learning-behaviour-on-a-robot/","publishdate":"2018-10-09T20:00:25.315Z","relpermalink":"/talk/imitating-the-drosophila-larval-learning-behaviour-on-a-robot/","section":"event","summary":" ","tags":null,"title":"Imitating the Drosophila Larval Learning Behaviour on a Robot","type":"event"},{"authors":null,"categories":null,"content":"We come up with a computational model of the insect mushroom body, constrained by biological findings of the insect brain. This model is able to acquire, forget and assimilate (transfer from short- to long-term) associative memories, represent a spectrum of motivation for the animal and drive its behaviour. We examine the capabilities of this model as an olfactory conditioning system and as part of the insect visual navigation mechanism\n","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"070d51a28892f81411bee8389f825d6d","permalink":"https://evgkanias.github.io/project/phd-thesis/","publishdate":"2018-09-01T00:00:00Z","relpermalink":"/project/phd-thesis/","section":"project","summary":"Thesis - Doctor of Philosophy","tags":["robotics","computer vision","olfactory learning","bio-inspired","insect","computational model","ant","fruitfly","circuit","memory","mushroom body","central complex","navigation","neuroscience"],"title":"Circuits for navigation strategies inspired by insects","type":"project"},{"authors":["Daniela Pacella","Evripidis Gkanias","Michael Mangan","Barbara Webb"],"categories":null,"content":" ","date":1532253600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532253600,"objectID":"6fadacbcbaf3d65cfa235eb7f4058504","permalink":"https://evgkanias.github.io/talk/neural-models-of-ant-navigation-in-a-realistic-3d-world/","publishdate":"2018-08-20T20:00:25.315Z","relpermalink":"/talk/neural-models-of-ant-navigation-in-a-realistic-3d-world/","section":"event","summary":" ","tags":null,"title":"Neural models of ant navigation in a realistic 3D world","type":"event"},{"authors":["Evripidis Gkanias","Theodoros Stouraitis","Jan M. Hemmi","Barbara Webb"],"categories":null,"content":"This is an embedded Microsoft Office presentation, powered by Office Online.\r","date":1501149609,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501149609,"objectID":"8a92ec58705628ca18c6100d2f7d5286","permalink":"https://evgkanias.github.io/talk/predator-evasion-by-a-robocrab/","publishdate":"2017-07-29T16:20:09.572Z","relpermalink":"/talk/predator-evasion-by-a-robocrab/","section":"event","summary":"We describe the first robot designed to emulate the specific perceptual and motor capabilities of the fiddler crab. An omnidirectional robot platform uses onboard computation to process images from a 360 degrees camera view, filtering them through a biological model of the crab’s ommatidia layout, extracting potential ‘predator’ cues, and executing an evasion response that also depends on contextual information. We show that, as for real crabs, multiple cues are needed for effective escape in different predator-prey scenarios.","tags":null,"title":"Predator Evasion by a Robocrab","type":"event"},{"authors":["Theodoros Stouraitis","Evripidis Gkanias","Barbara Webb"],"categories":null,"content":"","date":1500210051,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500210051,"objectID":"185aff324540bc7d66fa9b65972dcee4","permalink":"https://evgkanias.github.io/publication/predator-evasion-by-a-robocrab/","publishdate":"2017-07-16T13:00:51.237Z","relpermalink":"/publication/predator-evasion-by-a-robocrab/","section":"publication","summary":"We describe the first robot designed to emulate the specific perceptual and motor capabilities of the fiddler crab. An omnidirectional robot platform uses onboard computation to process images from a 360 degrees camera view, filtering them through a biological model of the crab’s ommatidia layout, extracting potential ‘predator’ cues, and executing an evasion response that also depends on contextual information. We show that, as for real crabs, multiple cues are needed for effective escape in different predator-prey scenarios.","tags":["robotics","computer vision","fiddler crab","behaviour"],"title":"Predator Evasion by a Robocrab","type":"publication"},{"authors":null,"categories":null,"content":"Outdoor navigation in natural environments remains a challenge for robotics. Recent breakthroughs in robot navigation have been dependent on specific sensor technologies, such as laser depth sensors and GPS, and advanced image processing. The ability of animals such as ants to navigate effectively without such power- and computation- hungry systems are a proof of principle that alternative cheaper approaches are viable. Ants also have specialised sensing, with a peripheral visual system that has evolved to be sensitive to crucial cues for navigation. Specifically, they make use of non-visible (to humans) light cues in the form of ultraviolet (UV) and polarised light detection. UV detection allows the important signal of the horizon shape against the sky to be easily distinguished. Polarised light detection provides an external compass cue of heading relative to the sun direction, even when only a small portion of the sky is visible.\nWe propose to build a sensory system that gathers the full range of light cues available to the ant, in its natural ecological situation, and to analyse the information contained in this signal. We will also analyse how the specific sensor layout (ommatidia array), peripheral receptor characteristics, and the motor behaviour of the ant may contribute to extracting salient information. The data will form a test-bed for comparison of algorithmic and neural models of the processing that underlies the navigation capabilities of the ant. To date, these cues have been considered separately but we believe the navigational success of this system depends on the specific combination. For example, the directional information in the polarised sky may form an important part of visual memories; and UV information may contribute to disambiguation of the polarisation pattern and the robustness of this information under different cloud conditions.\nThere has been a substantial increase in the last few years in research into insect neural pathways involved in processing these cues which has yet to be exploited in robot models. In particular there has been breakthrough work on the central brain mechanisms involved in decoding polarised light to obtain heading direction. There is also a rapidly increasing understanding of the circuits involved in learning, a key component of navigation capabilities.\n","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488326400,"objectID":"bc8680a19f164de7acddb81f1ab79bb9","permalink":"https://evgkanias.github.io/project/invisible-cues/","publishdate":"2017-03-01T00:00:00Z","relpermalink":"/project/invisible-cues/","section":"project","summary":"Design a sensor that transforms skylight into a compass direction.","tags":["robotics","computational model","bio-inspired","insect","ant","circuit","celestial","compass","central complex","navigation","skylight","polarisation"],"title":"Exploiting invisible cues for robot navigation in complex natural environments","type":"project"},{"authors":null,"categories":null,"content":"Biology provides the inspiration for a vision of small low-power devices that are able to learn rapidly and autonomously about environmental contingencies, enabling prediction and adaptive anticipatory action. Larval Drosophila have fewer than 10,000 neurons, yet express a variety of complex orientation and learning behaviours, including non-trivial anticipatory actions requiring context-dependent evaluation of the value of learned cues. Current computational learning theory cannot fully account for or replicate these capacities. We aim to develop a new foundation for understanding natural learning by developing a complete multilevel model of learning in larvae.\nOur aims are:\n to analyse at a fine scale how larval olfactory behaviour is controlled and altered by associative conditioning, linked to agent-based models that ground learning capabilities in ongoing sensorimotor control; to build one-to-one computational neural models that can be validated by exploiting the recent expansion of the Drosophila neurogenetic toolkit to gain unprecedented ability to characterise and manipulate neural circuits during unconstrained behaviour; to derive from these models novel, generalisable algorithms and circuit architectures that can be used to enhance the learning and anticipatory capabilities of machines.  ","date":1472688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472688000,"objectID":"ce2a9d390cfa7b30baf7cd689ab3d1d7","permalink":"https://evgkanias.github.io/project/minimal/","publishdate":"2016-09-01T00:00:00Z","relpermalink":"/project/minimal/","section":"project","summary":"We develop a new foundation for understanding natural learning by developing a complete multilevel model of learning in larvae","tags":["robotics","computational model","bio-inspired","insect","fruitfly","circuit","memory","mushroom body","neuroscience","olfactory learning"],"title":"Miniature Insect Model for Active Learning (Minimal)","type":"project"},{"authors":null,"categories":null,"content":"We create a semi-supervised structure of neural network, inspired by the physiology of neurons in fiddler crabs, and train it to adapt the evasion behaviour of fiddler crabs on potential predators, solving a complicated visuomotor problem (developed in Python using the Theano/Tensorflow-based ‘keras’ library\n","date":1454284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454284800,"objectID":"bb165e92cefdd0a8eb932e0b931d1480","permalink":"https://evgkanias.github.io/project/msc-thesis/","publishdate":"2016-02-01T00:00:00Z","relpermalink":"/project/msc-thesis/","section":"project","summary":"Disertation - Master of Science","tags":["robotics","computer vision","bio-inspired","computational model","fiddler crab","circuit","deep learning","machine learning","LSTM","behaviour"],"title":"Robocrab: data-driven adaptation of the evation behaviour in fiddler crabs","type":"project"},{"authors":null,"categories":null,"content":"The RePlay project has as its goal the development of a technology platform that shall provide access and interpretation of digital content for Traditional Sports and Games (TSG). It will enable multiple modes of training, coaching and knowledge sharing that will contribute to the increased participation and preservation of traditional sport in the future. This will be achieved by developing a base technology and methodologies for the digitisation of the art and forms of play of a set of representative sports. In the case of RePlay, this will be field based Gaelic team sports and Basque individual/doubles ball and court sports. The fundamental structure of these sports is extensible to a vast majority of traditional minority sports and mainstream sports.\nRePlay will consist of the design and implementation of a platform for the capture, annotation, indexing and provision of 3D sports content. It will include the analysis and specification of methodologies and ideal cost-effective hardware solutions for the extension of the project to other sports. The project will focus on the use of existing and near future 3D motion capture hardware. The project does not include the development of any hardware as an objective, as the market is already addressing this. It shall instead focus on the creation of the knowledge and underlying software tools that will provide a low-cost entry point to other TSG associations.\nRePlay will focus on the analysis, capture and modelling of the basic styles and techniques of play common to all participants or the “Local Hero” using low-cost capture techniques. However, RePlay will also use advanced professional grade capture techniques on “National Heroes”. A national hero, or a recognised elite player, develops their sporting prowess to an extent that is unique. This presents Intangible Cultural Heritage to be preserved, an opportunity to allow the young to try to learn and emulate their heroes, and a scientific opportunity to compare and analyse the evolution in the changes of styles of play over time. RePlay will also include work on retrospective analysis of sports via video content.\n","date":1441029600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441029600,"objectID":"0930f6f881f05e1fa6b49e0d31e0da6c","permalink":"https://evgkanias.github.io/project/replay/","publishdate":"2015-08-31T14:00:00Z","relpermalink":"/project/replay/","section":"project","summary":"Digitally capturing unique skills involved in European Traditional Sports and Games","tags":["machine learning","biomechanics","engineering","evaluation","human motion tracking","Microsoft kinect","Vicon","computer vision"],"title":"Replay","type":"project"},{"authors":null,"categories":null,"content":"We extended a Java library implementing Restricted Boltzmann Machines and Deep Belief Networks and we used it to examine how they perform in a variety of multi-label data-sets.\n","date":1359676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1359676800,"objectID":"7693d5d0f7bea749671c6d13552fe5e5","permalink":"https://evgkanias.github.io/project/bsc-thesis/","publishdate":"2013-02-01T00:00:00Z","relpermalink":"/project/bsc-thesis/","section":"project","summary":"Honours Thesis - Bachelor of Science","tags":["deep learning","machine learning","restricted Boltzmann machines","multi-label","deep belief networks","big data"],"title":"Deep learning algorithms for multi-label data","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://evgkanias.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]