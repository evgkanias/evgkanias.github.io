<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>central complex | Evripidis Gkanias</title>
    <link>https://evgkanias.github.io/tag/central-complex/</link>
      <atom:link href="https://evgkanias.github.io/tag/central-complex/index.xml" rel="self" type="application/rss+xml" />
    <description>central complex</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-gb</language><copyright>Â© 2022 Evripidis Gkanias</copyright><lastBuildDate>Wed, 01 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://evgkanias.github.io/media/icon_hu22afa8837ab305f0f3e5e2b9e7b7c4db_6290075_512x512_fill_lanczos_center_3.png</url>
      <title>central complex</title>
      <link>https://evgkanias.github.io/tag/central-complex/</link>
    </image>
    
    <item>
      <title>Insect neuro nano</title>
      <link>https://evgkanias.github.io/project/insect-neuro-nano/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/insect-neuro-nano/</guid>
      <description>&lt;p&gt;Implement a sensor that transforms skylight into a navigational output, by using nano-wires and molecular dyes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From skylight input to behavioural output: a computational model of the insect polarised light compass</title>
      <link>https://evgkanias.github.io/publication/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/</link>
      <pubDate>Thu, 18 Jul 2019 13:00:25 +0000</pubDate>
      <guid>https://evgkanias.github.io/publication/from-skylight-input-to-behavioural-output-a-computational-model-of-the-insect-polarised-light-compass/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Insect neuroethology of reinforcement learning</title>
      <link>https://evgkanias.github.io/project/phd-thesis/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/phd-thesis/</guid>
      <description>&lt;p&gt;Historically, reinforcement learning is a branch of machine learning founded on observations of how animals learn.
This involved collaboration between the fields of biology and artificial intelligence that was beneficial to both fields,
creating smarter artificial agents and improving the understanding of how biological systems function.
The evolution of reinforcement learning during the past few years was rapid, but substantially diverged from providing insights into how biological systems work,
opening a gap between reinforcement learning and biology.
In attempt to close this gap, this thesis studied the insect neuroethology of reinforcement learning, that is,
the neural circuits that underlie reinforcement-learning-related behaviour in insects.
The goal was to extract a biologically plausible plasticity function from insect-neuroscience data, use this to explain biological findings,
and compare it to more standard reinforcement learning models.&lt;/p&gt;
&lt;p&gt;Consequently, a novel dopaminergic plasticity rule was developed to approximate the function of dopamine as the plasticity mechanism between neurons in the insect brain.
This allowed a range of observed learning phenomena to happen in parallel, like memory depression, potentiation, recovery, and saturation.
In addition, by using anatomical data of connections between neurons in the mushroom body neuropils of the insect brain, the neural incentive circuit of dopaminergic and output neurons
was also explored. This, together with the dopaminergic plasticity rule, allowed for dynamic collaboration amongst parallel memory functions,
such as acquisition, transfer, and forgetting.
When tested on olfactory conditioning paradigms, the model reproduced the observed changes in the activity of the identified neurons in fruit flies.
It also replicated the observed behaviour of the animals and it allowed for flexible behavioural control. Inspired by the visual navigation system of desert ants,
the model was further challenged in the visual place recognition task.
Although a relatively simple encoding of the olfactory information was sufficient to explain odour learning,
a more sophisticated encoding of the visual input was required to increase the separability among the visual inputs and enable visual place recognition.
Signal whitening and sparse combinatorial encoding were sufficient to boost the performance of the system in this task.
The incentive circuit enabled increasing confidence when familiar places were presented in a sequence but not necessarily in the correct order.
Finally, the proposed model was challenged in delayed reinforcement tasks, and
preliminary results suggested that the temporal resolution of the task is crucial for meaningful memory dynamics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploiting invisible cues for robot navigation in complex natural environments</title>
      <link>https://evgkanias.github.io/project/invisible-cues/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://evgkanias.github.io/project/invisible-cues/</guid>
      <description>&lt;p&gt;Outdoor navigation in natural environments remains a challenge for robotics.
Recent breakthroughs in robot navigation have been dependent on specific sensor
technologies, such as laser depth sensors and GPS, and advanced image processing.
The ability of animals such as ants to navigate effectively without such
power- and computation- hungry systems are a proof of principle that
alternative cheaper approaches are viable. Ants also have specialised sensing,
with a peripheral visual system that has evolved to be sensitive to crucial
cues for navigation. Specifically, they make use of non-visible (to humans)
light cues in the form of ultraviolet (UV) and polarised light detection.
UV detection allows the important signal of the horizon shape against the sky
to be easily distinguished. Polarised light detection provides an external
compass cue of heading relative to the sun direction, even when only a small
portion of the sky is visible.&lt;/p&gt;
&lt;p&gt;We propose to build a sensory system that gathers the full range of light
cues available to the ant, in its natural ecological situation, and to analyse
the information contained in this signal. We will also analyse how the
specific sensor layout (ommatidia array), peripheral receptor characteristics,
and the motor behaviour of the ant may contribute to extracting salient
information. The data will form a test-bed for comparison of algorithmic and
neural models of the processing that underlies the navigation capabilities
of the ant. To date, these cues have been considered separately but we believe
the navigational success of this system depends on the specific combination.
For example, the directional information in the polarised sky may form an
important part of visual memories; and UV information may contribute to
disambiguation of the polarisation pattern and the robustness of this
information under different cloud conditions.&lt;/p&gt;
&lt;p&gt;There has been a substantial increase in the last few years in research into
insect neural pathways involved in processing these cues which has yet to be
exploited in robot models. In particular there has been breakthrough work on
the central brain mechanisms involved in decoding polarised light to obtain
heading direction. There is also a rapidly increasing understanding of the
circuits involved in learning, a key component of navigation capabilities.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
